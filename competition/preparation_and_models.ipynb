{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ae278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "#Leitura dos ficheiros\n",
    "train = pd.read_csv('datasets/training_data.csv',encoding='cp1252')\n",
    "test = pd.read_csv('datasets/test_data.csv',encoding='cp1252')\n",
    "\n",
    "#Funções auxiliares\n",
    "ordem = {'None':0, 'Low':1, 'Medium':2, 'High':3, 'Very_High':4}\n",
    "\n",
    "def round_pred(pred,predictions):\n",
    "    for n in pred:\n",
    "        n = int(round(n))\n",
    "        if n == 0: predictions.append('None')\n",
    "        elif n == 1: predictions.append('Low')\n",
    "        elif n == 2: predictions.append('Medium')\n",
    "        elif n == 3: predictions.append('High')\n",
    "        else: predictions.append('Very_High')\n",
    "            \n",
    "def hours(hour):\n",
    "    if hour > 0 and hour <= 8: return 'Noite'\n",
    "    elif hour > 8 and hour <= 16: return 'Hora_trabalho'\n",
    "    else: return 'Final_dia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0824d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento de dados\n",
    "\n",
    "#Feriados - Dias da semana - Estações\n",
    "feriados = ['2018-01-01', '2018-02-13', '2018-03-30', '2018-04-01', '2018-04-25', \n",
    "            '2018-05-01', '2018-05-31', '2018-06-10', '2018-08-15', '2018-10-05', \n",
    "            '2018-11-01', '2018-12-01', '2018-12-08', '2018-12-25', '2019-01-01',\n",
    "            '2019-03-05', '2019-04-19', '2019-04-21', '2019-04-25', '2019-05-01',\n",
    "            '2019-06-10', '2019-06-20', '2019-08-15', '2019-10-05', '2019-11-01', \n",
    "            '2019-12-01', '2019-12-08', '2019-12-25']\n",
    "\n",
    "for index,row in train.iterrows():\n",
    "    data_hour = row[1].split(' ')\n",
    "    data = data_hour[0]\n",
    "    hour_split = data_hour[1]\n",
    "    hour = hour_split.split(':')[0]\n",
    "    month = data.split('-')[1]\n",
    "    train.at[index,'Parte_dia'] = hours(int(hour))\n",
    "    if month in ['01','02','03']: train.at[index,'Estacao'] = 'Inverno'\n",
    "    elif month in ['04','05','06']: train.at[index,'Estacao'] = 'Primavera'\n",
    "    elif month in ['07','08','09']: train.at[index,'Estacao'] = 'Verao'\n",
    "    else: train.at[index,'Estacao'] = 'Outono'\n",
    "    dia = pd.Timestamp(data)\n",
    "    train.at[index,'Dia'] = dia.day_name()\n",
    "    if data in feriados: train.at[index,'Feriado'] = True\n",
    "    else: train.at[index,'Feriado'] = False\n",
    "        \n",
    "for index,row in test.iterrows():\n",
    "    data_hour = row[1].split(' ')\n",
    "    data = data_hour[0]\n",
    "    hour_split = data_hour[1]\n",
    "    hour = hour_split.split(':')[0]\n",
    "    month = data.split('-')[1]\n",
    "    test.at[index,'Parte_dia'] = hours(int(hour))\n",
    "    if month in ['01','02','03']: test.at[index,'Estacao'] = 'Inverno'\n",
    "    elif month in ['04','05','06']: test.at[index,'Estacao'] = 'Primavera'\n",
    "    elif month in ['07','08','09']: test.at[index,'Estacao'] = 'Verao'\n",
    "    else: test.at[index,'Estacao'] = 'Outono'\n",
    "    dia = pd.Timestamp(data)\n",
    "    test.at[index,'Dia'] = dia.day_name()\n",
    "    if data in feriados: test.at[index,'Feriado'] = True\n",
    "    else: test.at[index,'Feriado'] = False\n",
    "        \n",
    "\n",
    "del train['city_name']\n",
    "del test['city_name']\n",
    "del train['record_date']\n",
    "del test['record_date']\n",
    "del train['AVERAGE_TEMPERATURE']\n",
    "del test['AVERAGE_TEMPERATURE']\n",
    "del train['AVERAGE_ATMOSP_PRESSURE']\n",
    "del test['AVERAGE_ATMOSP_PRESSURE']\n",
    "del train['AVERAGE_HUMIDITY']\n",
    "del test['AVERAGE_HUMIDITY']\n",
    "del train['AVERAGE_WIND_SPEED']\n",
    "del test['AVERAGE_WIND_SPEED']\n",
    "del train['AVERAGE_CLOUDINESS']\n",
    "del test['AVERAGE_CLOUDINESS']\n",
    "del train['AVERAGE_PRECIPITATION']\n",
    "del test['AVERAGE_PRECIPITATION']\n",
    "del train['AVERAGE_RAIN']\n",
    "del test['AVERAGE_RAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d68d4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparação para colocar nos modelos\n",
    "X = train.drop(['AVERAGE_SPEED_DIFF'],axis=1) # Dataset de treino\n",
    "Y = train['AVERAGE_SPEED_DIFF'].to_frame()    #        \"\"\n",
    "Y_2 = train['AVERAGE_SPEED_DIFF'].map(ordem)  #        \"\"\n",
    "X_teste = test # Dataset de teste\n",
    "\n",
    "luminosity = LabelEncoder()\n",
    "feriado = LabelEncoder()\n",
    "day = LabelEncoder()\n",
    "season = LabelEncoder()\n",
    "hour = LabelEncoder()\n",
    "\n",
    "X['LUMINOSITY_n'] = luminosity.fit_transform(X['LUMINOSITY'])\n",
    "X['Feriado_n'] = feriado.fit_transform(X['Feriado'])\n",
    "X['Dia_n'] = day.fit_transform(X['Dia'])\n",
    "X['Estacao_n'] = season.fit_transform(X['Estacao'])\n",
    "X['Parte_dia_n'] = hour.fit_transform(X['Parte_dia'])\n",
    "\n",
    "X = X.drop(['LUMINOSITY','Dia','Estacao','Parte_dia','Feriado'],axis=1)\n",
    "\n",
    "luminosity_t = LabelEncoder()\n",
    "feriado_t = LabelEncoder()\n",
    "day_t = LabelEncoder()\n",
    "season_t = LabelEncoder()\n",
    "hour_t = LabelEncoder()\n",
    "\n",
    "X_teste['LUMINOSITY_n'] = luminosity_t.fit_transform(X_teste['LUMINOSITY'])\n",
    "X_teste['Feriado_n'] = feriado_t.fit_transform(X_teste['Feriado'])\n",
    "X_teste['Dia_n'] = day_t.fit_transform(X_teste['Dia'])\n",
    "X_teste['Estacao_n'] = season_t.fit_transform(X_teste['Estacao'])\n",
    "X_teste['Parte_dia_n'] = hour_t.fit_transform(X_teste['Parte_dia'])\n",
    "\n",
    "\n",
    "X_teste = X_teste.drop(['LUMINOSITY', 'Dia','Estacao','Parte_dia','Feriado'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32209e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.5511569522073306\n",
      "MSE:  0.46447359920153003\n",
      "RMSE:  0.6815229997597514\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "#Sem dataset de teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y_2, test_size=0.3, random_state=2021)\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print('MAE: ', metrics.mean_absolute_error(y_test,pred))\n",
    "print('MSE: ', metrics.mean_squared_error(y_test,pred))\n",
    "print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test,pred)))\n",
    "\n",
    "#Com datasat de teste\n",
    "#lr.fit(X,Y_2)\n",
    "#pred = lr.predict(X_teste)\n",
    "#predictions = []\n",
    "#round_pred(pred,predictions)\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea7844f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651663405088063"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic Regression\n",
    "logr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "#Sem dataset de teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,np.ravel(Y), test_size=0.3, random_state=2021)\n",
    "logr.fit(X_train,y_train)\n",
    "predictions = logr.predict(X_test)\n",
    "accuracy_score(y_test, predictions)\n",
    "\n",
    "#Com datasat de teste\n",
    "#logr.fit(X,np.ravel(Y))\n",
    "#predictions = logr.predict(X_teste)\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e40fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[234   3  66   1  30]\n",
      " [  7 241  63  81   0]\n",
      " [ 72  84 326   7   1]\n",
      " [  1 107   4 562   0]\n",
      " [ 40   0   1   0 113]]\n",
      "0.7221135029354208\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state = 2021)\n",
    "\n",
    "#Sem dataset de teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y, test_size=0.3, random_state=2021)\n",
    "dtc.fit(X_train,y_train)\n",
    "predictions = dtc.predict(X_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "#Com datasat de teste\n",
    "#dtc.fit(X,Y)\n",
    "#predictions = dtc.predict(X_teste)\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17aad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7597847358121331\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "svc = SVC(random_state=2021)\n",
    "\n",
    "#Sem dataset de teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,np.ravel(Y), test_size=0.3, random_state=2021)\n",
    "svc.fit(X_train,y_train)\n",
    "predictions = svc.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "#Com datasat de teste\n",
    "#svc.fit(X,np.ravel(Y))\n",
    "#predictions = svc.predict(X_teste)\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2934a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.772 total time=   0.8s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.782 total time=   0.7s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.779 total time=   0.8s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.796 total time=   0.9s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.778 total time=   0.9s\n",
      "0.7865003668378576\n"
     ]
    }
   ],
   "source": [
    "#GridSearch\n",
    "param_grid = {'C': [1000], 'gamma': [0.0001],'kernel': ['rbf']}\n",
    "grid = GridSearchCV(SVC(random_state=2021),param_grid,refit=True,verbose=3)\n",
    "\n",
    "#Sem dataset de teste\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,np.ravel(Y), test_size=0.3, random_state=2021)\n",
    "grid.fit(X_train,y_train)\n",
    "predictions = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "#Com datasat de teste\n",
    "#grid.fit(X,Y)\n",
    "#predictions = grid.predict(X_teste)\n",
    "\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7f78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = open(\"submissions/submission23.csv\", \"w\", newline='')\n",
    "writer = csv.writer(submission)\n",
    "writer.writerow(['RowId', 'Speed_Diff'])\n",
    "rowId = list(range(0, 1500))\n",
    "for i in range(1500):\n",
    "    writer.writerow([rowId[i]+1, predictions[i]])\n",
    "\n",
    "submission.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
